<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 13.3 学习增强系统的落地挑战

虽然学习增强系统的核心是利用机器学习来解决计算机系统的问题，但构建和落地一个学习增强系统并不仅仅是选取和整合已有的模型。在 “*Hidden Technical Debt in Machine Learning Systems*” 这篇论文里，作者统称相关的落地痛点和考虑要素为隐藏技术债务（Hidden Technical Debt）。基于从过去的科研和产品经验里，我们从多个维度来讨论学习增强系统落地的痛点和考虑要素。本章包含以下内容：

- [13.3 学习增强系统的落地挑战](#133-学习增强系统的落地挑战)
  - [13.3.1 系统数据](#1331-系统数据)
  - [13.3.2 系统模型](#1332-系统模型)
  - [13.3.3 系统动态性](#1333-系统动态性)
  - [13.3.4 系统正确性](#1334-系统正确性)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)

## 13.3.1 系统数据

机器学习的基本思维是从数据中学习。理论上，如果训练数据集越大越多元化越正确，则对机器学习越有利。幸运的是，采集多维度的系统数据普遍来说并不是一件困难的事，尤其现代的计算机系统普遍有着完善的行为监测机制和精细的日志。另外，线上线下的系统评测（Benchmarks）已经是一个常见的做法。基于系统评测，我们理论上能在相对可控的状态下，采集到大量的系统行为数据。但是，使用这些系统数据来训练模型存在以下的难点。

首先，许多计算机系统数据的原始格式对机器学习并不友好。不同的监测机制有着不同的格式。而且，因为现代系统的接口设计主要是面向开发者的，计算机系统的行为监测机制和精细的日志的设计目标为帮助工程师来处错，很多的系统数据格式并不是机器学习熟悉的 “输入--输出” 结构格式。一个简单的例子是当操作系统内核崩溃时产生的调试信息（Kernel Crash Dump）。所以，落地学习增强系统需要能自动化地转化并统一所有的系统数据流。再往更深的一步去探索，统一这些数据流还需要注意如何关联系统指令和采样反馈。对于机器学习而言，前者为训练集的输入（比如系统参数），后者则是输出（比如系统性能）。但是，在很多情况下却很难做到正确的关联。一个例子就是系统里的缓冲存储器需要适当地预热；如果太早采集反馈会得到错误的结果，但太晚采集则会浪费大量的等候时间。

另一个难点是，工程师需要判断哪些数据需保留为训练数据集，尤其是当系统能输出多维度的系统数据流。我们这边用数据库为一个例子 —— 工业界常用的键值数据库 RocksDB 有超过 50 个设定参数，能记录超过 100 性能指标。但是，判断哪一个设定参数和那一个性能指标有很大的相关性并不是一个简单的问题。这问题类似于机器学习的特征选择 (Feature Selection)。

系统数据可能会有大量的噪声和异常值，而造成模型训练的准确度过低。一个常见的案例是当我们用机器学习模型来预测时间类性能指标，如云服务的请求延迟或网路传输延迟。即使重复相同的系统评测也很有可能采集到不同的延迟数据。这是因为能影响系统延迟的因素很多，不光是系统的设定参数。这些因素可能包含从处理器的缓存策略，操作系统的资源分配策略和线程，虚拟主机上其他租户的负载，网路的环境和负载，到用户的流量，等等。虽然我们可以取多次延迟数据的平均或最低值来训练模型，但重复相同的系统评测线性地增加了时间开销。

另外一个系统评测的痛点是时间上的开销使得无法在有效的时间下完成大量的系统评测；比如，每一次的系统评测需要等待系统完成初始化和暖机，并能输出稳定的性能指标。在我们之前的经验，一个完整的系统评测普遍需要至少几分钟，所以采集完所有的数据可能需要几天的时间。即使是在模拟和仿真的环境下，一个完整的系统评测（比如硬件模拟）甚至有可能需要几天的时间才能完成，更不用说模拟和仿真的真实性对于正确性的影响（请见 [13.3.4 章节](#1334-系统正确性)）。其实，直觉上，我们应该用长期的全局最优的眼光来选择能带来信息增益最大的系统评测，而不是随机地完成越多的系统评测。所以，一个有趣的想法是如何使用“探索--利用”（Exploration--Exploitation）的策略来降低系统评测的次数。在 [13.2 章节](#132-学习增强系统的应用)里，我们提到过 Exploration 探索未知空间获取更多信息，而 Exploitation 利用当前已知信息做决策。

## 13.3.2 系统模型

由于学习增强系统的决策是基于机器学习模型，模型的时间和资源开销是系统运维必须考虑的一部分。我们这里用 Learned Ranker 这个项目来做一个例子。Learned Ranker 作者的目标是利用机器学习来加速规则匹配系统。一个常见的规则匹配系统是网路防火墙。基本上来说，规则匹配系统的任务在于从所有内建的规则中，找出符合当前输入的字符串。所以，规则匹配的速度大大影响了整个系统的延迟和吞吐量。基于每个网路封包，Learned Ranker 为防火墙预先排列规则。在最理想的情况下，最有可能匹配上的规则就会先被防火墙处理，进而大大降低防火墙需要为每个封包处理的规则数量。Learned Ranker 的作者尝试用逻辑回归（Logistic Regression，LR)，深度神经网络（DNN），和循环神经网络（RNN）。有趣的是虽然 RNN 能更准确得预测最有可能匹配上的规则，但从系统的整体开销的角度来看，提升并不明显。原因在于，相比于 LR 和 DNN，RNN 模型需要更多的资源和时间来做推理。所以，RNN 在规则匹配上所节约到的时间，有很大一部分都变相地被模型推理消耗掉。

对于手写的启发式算法，系统工程师可以优化代码和逻辑来降低时间上和资源上的开销。但是，机器学习模型的架构（比如深度神经网络的神经元）并不是系统工程师能轻易读懂和手动优化的。一个有趣的想法是如何使用自动机器学习（AutoML）的技术来帮助系统工程师设计针对场景时间和资源限制的模型，包括模型的架构和超参。

## 13.3.3 系统动态性

现代计算机系统在线上生产环境有着强烈的动态性，而这些动态性使得系统的行为随着时间而改变。这些动态性来自于几个因素。第一个因素是系统的负载。比如，搜索引擎随着用户的数量和搜索关键字而变；视频流系统的负载随着视频的选择和解析度而变；数据库的负载随着读写请求和比例而变。第二个因素是系统的部署。一个典型的例子是微服务的架构。由于微服务的架构隔离了每个系统的子服务，这些子服务可以被像 Kubernetes 这类的容器管理平台来随着系统的负载而自动扩容。扩容改变了子服务的数量和部署，也因此改变了系统的特性和性能。第三个因素是系统的环境。这包括软件和硬件的升级，多租户伺服器上的其他租户的资源使用，等等。不难理解，在这些情况下，机器学习模型对于任务的一些假设会随着时间而不成立。但有趣的是，这些模型的假设不仅仅在数据分布，也反应在模型的架构。我们下面

系统动态性意味着机器学习模型对于任务的一些假设会随着时间而不成立。不难理解，学习增强系统的机器学习模型必须要能自适应，以便做出对的决策。比如，如果系统的当前行为是模型训练时不曾见过的，学习增强系统需要训练机器学习模型。一个有趣的想法是整合增量学习和线上学习，但这些方法存在一定的限制。这是由于系统动态性对模型的假设改变不仅仅是在数据分布上，也可能反应在模型的架构上。在这情况下，我们不能只重新训练模型，而是需要重新设计模型的架构。比如，如果微服务的应用被扩容到之前两倍的大小，这改变了集群里节点的数量。所以，模型的输入维度和架构也需要做相对应的改动，来接受增加的子服务。反之，当微服务的应用的部署规模被缩小时，我们也需要新模型。另外，线上学习有灾难性遗忘（Catastrophic Forgetting）的问题 —— 即神经网络在新数据上训练后，权重发生变化，导致神经网络遗忘旧数据上学习到的知识。虽然一种解决灾难性遗忘的办法是保存历史数据来做重复训练，但这造成了储存空间的开销。有些系统数据甚至因为隐私的原因，不能被长久保存。

## 13.3.4 系统正确性

机器学习的预测和推理自身带有不确定性。当学习增强系统的决策是基于不确定的模型预测，所做的系统决策很有可能会是不合理的（或甚至太激进）。比如，当模型无法准确地预测一个系统的性能指标，学习增强系统则无法保证参数调优的效果。上线一组不适当的系统参数可能会造成系统的性能大幅度地下降，甚至系统崩溃。另一个例子是自动驾驶汽车。我们要减低行驶过程中所遇到的新型物体对于汽车安全的影响，如骑自行车的人和动物等等。但是，要做到这一点，我们需要了解什么时候汽车对于它看到的对象有很大的不确定性，以及如何最好地解决这种不确定性。然而，机器学习模型不像手写的启发式算法，模型的架构（比如深度神经网络的神经元）并不是系统工程师能轻易读懂的。即使是机器学习专家，也很难知道模型何时不确定以及如何计算不确定性。另外，由于机器学习模型架构有别于代码，传统的软件测试方法很难适用于学习增强系统。所以，如何降低机器学习不确定性对系统正确性的影响是一个至关重要的挑战。

现阶段，解决这问题的方法有以下三大思路。

第一种思路是降低模型的不确定性 —— 尽可能地采集越多的数据来训练和设计模型，也尽可能地采集模型有可能预测错误的输入。但是，对于有些计算机系统，这思路需要大量的时间和资源开销，因为牵扯到 [13.3.1 章节](#1331-系统数据)讨论过的系统数据的低采样效率。虽然训练也可以在仿真环境下进行，这需要我们对仿真环境的真实性有足够的信心。一个有趣的想法是如何利用机器学习的增量学习和线上学习，来整合线下测试环境和线上生产环境所采集到的训练数据。另外，在这方面我们可以参考强化学习的一个相关的讨战：仿真迁移到真实（Simulation to Real，Sim2Real）。目前，Sim2Real 的算法大致可以分为以下几种类别。第一种是域随机化 （Domain Randomization） —— 对仿真环境的参数加入随机数（如物体颜色等），来使仿真环境中的参数大概率地包含了真实环境中的参数。第二种是域适应 (Domain Adaptation) —— 更新另一个已经有大量数据的仿真环境，来使其靠近真实环境的数据分布。域随机化和域适应都是属于无监督，但是域适应普遍来说会需要比域随机化更多的真实环境数据。第三种是系统辨识（System Identification）—— 为真实环境建立一个精确的数学模型，使仿真环境更加真实。

第二种思路是使模型有能力量化，解释，和反馈一个推理的不确定性。一个简单的例子是高斯过程模型 （Gaussian Process）—— 高斯过程是一种概率模型，无论是回归或者分类预测都能以高斯分布标准差的方式，给出预测置信区间估计 （Confidence Interval）。基本上，在已知的数据点周围，置信区间较小（对于预测的信心越大），离已知点越远，置信区间越大（对于预测的信心越小）。基于置信区间估计，学习增强系统可以间接地评估一个决策。对于信心较小的预测，学习增强系统可以用人机回圈的方式来得到专家的帮助。但是，高斯过程模型之外，目前大多数的模型都无法提供预测置信区间估计。

第三种思路是利用手写的规则来线上评估模型驱动的决策。在这思路下，工程师把经验上能产生系统错误的条件写成规则。如果一个模型驱动的决策符合任意一条规则，则拦截其决策。这思路的好处在于这些手写规则是可被工程师理解，并随时更改的。但是，写规则可能会需要工程师大量的精力和时间。

最后，我们想讨论因为当决策太激进而影响系统正确性的可能性。这常发生在利用机器学习来驱动系统行为调整的场景，比如系统参数的调优。激进的决策可以是因为计算机系统的行为太频繁地或太大幅度地被调整。这两种情况都有可能造成系统的不稳定。当计算机系统的行为太频繁地被调整，计算机系统没有足够的时间来达到稳定的状态。理论上，这时的系统反馈还不能正确地表达上个行为调整的结果，所以并不应该作为下个行为调整的依据。一个例子是在扩容微服务或参数调优之后，微服务需要一段时间来清空之前堆积的请求。另外，当计算机系统的行为太大幅度地被调整（例如太多的系统设定参数在同一时间被调整），计算机系统也可能需要一段时间来达到稳定的状态。

## 小结与讨论

虽然学习增强的系统设计思维能解决很多现有的计算机系统挑战，但它也可能增加系统落地的复杂度。所以，构建学习增强系统并不仅仅是选取和整合复杂的模型，而是一个严谨的计算机系统与机器学习的同协设计问题。最后，我们引用图灵奖得主 Edsger Dijkstra 的一句话：“Simplicity is a great virtue but it requires hard work to achieve it”。

## 参考文献

1. D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. 2015. [*Hidden Technical Debt in Machine Learning Systems*](https://dl.acm.org/doi/10.5555/2969442.2969519). In Proceedings of the 28th International Conference on Neural Information Processing Systems (NIPS'15). MIT Press.

2. Tianyin Xu, Long Jin, Xuepeng Fan, Yuanyuan Zhou, Shankar Pasupathy, and Rukma Talwadker. 2015. [*Hey, You Have Given Me Too Many Knobs!: Understanding and Dealing with Over-Designed Configuration in System Software*](https://doi.org/10.1145/2786805.2786852). In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE '15). Association for Computing Machinery.

3. Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and Pieter Abbeel. 2017. [*Domain Randomization for Transferring Deep Neural Networks From Simulation To The Real World*](https://doi.org/10.1109/IROS.2017.8202133). In Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '17). IEEE.

4. Xue Bin Peng, Marcin Andrychowicz, Wojciech Zaremba, and Pieter Abbeel. 2018. [*Sim-to-Real Transfer of Robotic Control with Dynamics Randomization*](https://doi.org/10.1109/ICRA.2018.8460528). In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA '18). IEEE.

5. Zhao Lucis Li, Chieh-Jan Mike Liang, Wei Bai, Qiming Zheng, Yongqiang Xiong, and Guangzhong Sun. 2019. [*Accelerating Rule-matching Systems with Learned Rankers*](https://www.usenix.org/conference/atc19/presentation/li-zhao). In Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference (ATC '19). USENIX Association.

6. Chieh-Jan Mike Liang, Hui Xue, Mao Yang, Lidong Zhou, Lifei Zhu, Zhao Lucis Li, Zibo Wang, Qi Chen, Quanlu Zhang, Chuanjie Liu, and Wenjun Dai. 2020. [*AutoSys: The Design and Operation of Learning-Augmented Systems*](https://dl.acm.org/doi/abs/10.5555/3489146.3489168). In Proceedings of the 2020 USENIX Conference on Usenix Annual Technical Conference (ATC '20). USENIX Association.
